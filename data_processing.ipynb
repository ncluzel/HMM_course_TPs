{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff51f4-6c3e-4b69-a693-89db6a1702d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "folder_name\n",
    "root_dir = '/content/gdrive/My Drive/'\n",
    "base_dir = root_dir + 'Colab Notebooks/' + folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b366c-9f4c-4a10-9c19-004d3add8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import pymc as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375de553-d29b-40bb-90d3-75486ba4a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_95CI(signal, alpha=5.0):\n",
    "    \"\"\"Computes the (default to 95%) confidence intervals of a sequential signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : {array-like} of shape (n_samples, n_timesteps).\n",
    "    The matrix of samples. Each row represents a sample, while each column is associated to a timestep.\n",
    "\n",
    "    alpha : float.\n",
    "    1 - CI_range, where CI_range represents the range of the confidence interval.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CI95_lower : {array} of shape (n_timesteps, ).\n",
    "    The lower bound of the (1 - alpha) confidence interval.\n",
    "\n",
    "    CI95_upper : {array} of shape (n_timesteps, ).\n",
    "    The upper bound of the (1 - alpha) confidence interval.\n",
    "    \"\"\"\n",
    "    CI95_lower = []\n",
    "    CI95_upper = []\n",
    "\n",
    "    for timestep in range(signal.shape[1]):\n",
    "\n",
    "        drawn_at_time_t = signal[:,timestep] # Gather the samples at time t\n",
    "        lower_p = alpha / 2.0 # Computes the lower bound\n",
    "        lower = np.percentile(drawn_at_time_t, lower_p) # Retrieves the observation at the lower percentile index\n",
    "        upper_p = (100 - alpha) + (alpha / 2.0) # Computes the upper bound\n",
    "        upper = np.percentile(drawn_at_time_t, upper_p) # Retrieves the observation at the upper percentile index\n",
    "\n",
    "        CI95_lower.append(lower)\n",
    "        CI95_upper.append(upper)\n",
    "\n",
    "    return np.array(CI95_lower), np.array(CI95_upper)\n",
    "\n",
    "\n",
    "def normal_distribution_pdf(x, loc=0, scale=1):\n",
    "    \"\"\"Computes the normal probability density function (PDF) for each value in the input vector x.\n",
    "    NB : Empirically much faster than scipy's, probably related to sample size I guess.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : {array} of shape (n_samples, ).\n",
    "    The array upon which the PDF is going to be applied.\n",
    "\n",
    "    loc : float.\n",
    "    The mean of the normal distribution.\n",
    "\n",
    "    scale : float.\n",
    "    The standard deviation of the normal distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pdf : {array} of shape (n_samples, ).\n",
    "    The PDF related to the input vector x.\n",
    "    \"\"\"\n",
    "    A = 1 / (scale * np.sqrt(2 * np.pi))\n",
    "    B = - (1/2) * ((x - loc)/ scale) ** 2\n",
    "\n",
    "    return A * np.exp(B)\n",
    "\n",
    "def approx_standard_normal_cdf_sw(x, loc=0, scale=1):\n",
    "    \"\"\"Computes the normal cumulative distribution function (CDF) for each value in the input vector x,\n",
    "    using Page's approximation formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : {array} of shape (n_samples, ).\n",
    "    The array upon which the CDF is going to be applied.\n",
    "\n",
    "    loc : float.\n",
    "    The mean of the normal distribution.\n",
    "\n",
    "    scale : float.\n",
    "    The standard deviation of the normal distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cdf : {array} of shape (n_samples, ).\n",
    "    The CDF related to the input vector x.\n",
    "    \"\"\"\n",
    "    xx = (x - loc) / scale\n",
    "    return 0.5 * (1.0 + np.tanh(np.sqrt(2.0 / np.pi) * (xx + 0.044715 * xx**3)))\n",
    "\n",
    "def censored_normal_logcdf(lod, eps, latent):\n",
    "    \"\"\"Computes the logarithm of the normal cumulative distribution function (CDF) for each observation in the input vector lod,\n",
    "    based on the assumption that lod|latent \\sim \\mathcal{N}(latent, eps**2) in pyMC's framework.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lod : {array} of shape (n_steps, ).\n",
    "    The array of sequential observations. Can contain np.nan values corresponding to unobserved timesteps.\n",
    "\n",
    "    eps : float.\n",
    "    The standard deviation of the observations w.r.t the latent variable.\n",
    "\n",
    "    latent : {array} of shape (n_steps, ).\n",
    "    The array of the sequential values for the latent variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cdf : {array} of shape (n_steps, ).\n",
    "    The CDF related to the input vector lod.\n",
    "    \"\"\"\n",
    "    return pm.logcdf(pm.Normal.dist(mu=latent, sigma=eps), lod)\n",
    "\n",
    "def censored_uniform_logcdf(lod, a, b):\n",
    "    \"\"\"Computes the logarithm of the uniform cumulative distribution function (CDF) for each observation in the input vector lod,\n",
    "    based on the assumption that lod|latent \\sim \\mathcal{U}(a, b) in pyMC's framework.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lod : {array} of shape (n_steps, ).\n",
    "    The array of sequential observations. Can contain np.nan values corresponding to unobserved timesteps.\n",
    "\n",
    "    a : float.\n",
    "    Lower bound of the uniform distribution.\n",
    "\n",
    "    b : {array} of shape (n_steps, ).\n",
    "    Upper bound of the uniform distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cdf : {array} of shape (n_steps, ).\n",
    "    The CDF related to the input vector lod.\n",
    "    \"\"\"\n",
    "    return pm.logcdf(pm.Uniform.dist(lower=a, upper=b), lod)\n",
    "\n",
    "\n",
    "def censored_normal_logcdf_LoQ(loqd, eps, latent):\n",
    "    \"\"\"Computes the logarithm of the normal cumulative distribution function (CDF) for each observation in the input vector value,\n",
    "    based on the assumption that value|latent \\sim \\mathcal{N}(latent, eps**2) in pyMC's framework.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : {array} of shape (n_steps, ).\n",
    "    The array of sequential observations. Can contain np.nan values corresponding to unobserved timesteps.\n",
    "\n",
    "    eps : float.\n",
    "    The standard deviation of the observations w.r.t the latent variable.\n",
    "\n",
    "    latent : {array} of shape (n_steps, ).\n",
    "    The array of the sequential values for the latent variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cdf : {array} of shape (n_steps, ).\n",
    "    The CDF related to the input vector value.\n",
    "    \"\"\"\n",
    "    contrib_a = pm.math.exp(censored_normal_logcdf(loqd[:,0], eps, latent))\n",
    "    contrib_b = pm.math.exp(censored_normal_logcdf(loqd[:,1], eps, latent))\n",
    "    return pm.math.log(contrib_b - contrib_a)\n",
    "\n",
    "def censored_uniform_logcdf_LoQ(loqd, a, b):\n",
    "    \"\"\"Computes the logarithm of the uniform cumulative distribution function (CDF) for each observation in the input vector value,\n",
    "    based on the assumption that value|latent \\sim \\mathcal{U}(a, b) in pyMC's framework.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : {array} of shape (n_steps, ).\n",
    "    The array of sequential observations. Can contain np.nan values corresponding to unobserved timesteps.\n",
    "\n",
    "    a : float.\n",
    "    Lower bound of the uniform distribution.\n",
    "\n",
    "    b : {array} of shape (n_steps, ).\n",
    "    Upper bound of the uniform distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cdf : {array} of shape (n_steps, ).\n",
    "    The CDF related to the input vector value.\n",
    "    \"\"\"\n",
    "    contrib_a = pm.math.exp(censored_uniform_logcdf(loqd[:,0], a, b))\n",
    "    contrib_b = pm.math.exp(censored_uniform_logcdf(loqd[:,1], a, b))\n",
    "    return pm.math.log(contrib_b - contrib_a)\n",
    "\n",
    "class SCOU():\n",
    "    \"\"\"\n",
    "    Bayesian implementation of the SCOU algorithm.\n",
    "\n",
    "    SCOU is an extended Kalman Smoother, taking into consideration\n",
    "    left-censored values as well as outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_out_frozen : bool, default=False\n",
    "        Whether to estimate the a priori outlier probability. If set\n",
    "        to False, a deterministic value will be used.\n",
    "\n",
    "    p_out_deterministic : float, default=None\n",
    "        The value to be used for p_out if p_out_frozen is set to True.\n",
    "\n",
    "    tuning_iters : int, default=4000\n",
    "        The number of tuning iterations used for the NUTS MCMC sampler.\n",
    "\n",
    "    sampling_iters : int, default=2000\n",
    "        The number of sampling iterations used for the NUTS MCMC sampler.\n",
    "\n",
    "    nb_chains : int, default=3\n",
    "        The number of Markov chains used for the NUTS MCMC sampler.\n",
    "\n",
    "    export_chains : bool, default=False\n",
    "        Whether to export the chains of parameters in a *.nc file.\n",
    "\n",
    "    export_name : string, default='default.nc'\n",
    "        The name of the export file if export_chains is set to True.\n",
    "\n",
    "    RW_order : {1, 2}, default=1\n",
    "        The order of the gaussian random walk of the underlying process.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    latent_posterior_distribution : array of shape (n_samples, n_steps)\n",
    "        The posterior distribution of the latent variable.\n",
    "\n",
    "    muX : array of shape (n_steps, )\n",
    "        The average signal of the latent variable, performed over all samples.\n",
    "\n",
    "    CIU : array of shape (n_steps, )\n",
    "        The upper bound of the 95% CI of the latent variable.\n",
    "\n",
    "    CIL : array of shape (n_steps, )\n",
    "        The lower bound of the 95% CI of the latent variable.\n",
    "\n",
    "    pointwise_pout : array of shape (n_steps, )\n",
    "        The posterior probability of each observation to be an outlier.\n",
    "\n",
    "    SCOU_model :\n",
    "\n",
    "    SCOU_traces :\n",
    "\n",
    "    T_ronde :\n",
    "\n",
    "    borne_inf :\n",
    "\n",
    "    borne_sup :\n",
    "\n",
    "    unobserved_indexes :\n",
    "\n",
    "\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This algorithm was tailor-made to meet the expectations of the Obepine research consortium\n",
    "    during the Covid-19 pandemic in terms of microbiological data processing.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "\n",
    "    .. [1] M. Courbariaux et al., \"A Flexible Smoother Adapted to Censored Data\n",
    "           With Outliers and Its Application to SARS-CoV-2 Monitoring in Wastewater\",\n",
    "           Frontiers in Applied Mathematics and Statistics, 2022.\n",
    "           https://doi.org/10.3389/fams.2022.836349\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> TODO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observations,\n",
    "                 censoring_threshold_lod_vect=np.array([]),\n",
    "                 censoring_threshold_loq_vect=np.array([]),\n",
    "                 p_out_frozen=False,\n",
    "                 p_out_deterministic=None,\n",
    "                 tuning_iters=4000,\n",
    "                 sampling_iters=2000,\n",
    "                 nb_chains=3,\n",
    "                 export_chains=False,\n",
    "                 export_name='default.nc',\n",
    "                 RW_order=1):\n",
    "\n",
    "        self.observations = observations\n",
    "        self.censoring_threshold_lod_vect = censoring_threshold_lod_vect\n",
    "        self.censoring_threshold_loq_vect = censoring_threshold_loq_vect\n",
    "        self.n_steps = self.observations.shape[0]\n",
    "        self.rng = np.random.default_rng(666)\n",
    "        self.tuning_iters = tuning_iters\n",
    "        self.sampling_iters = sampling_iters\n",
    "        self.nb_chains = nb_chains\n",
    "        self.export_name = export_name\n",
    "        self.export_chains = export_chains\n",
    "        self.p_out_frozen = p_out_frozen\n",
    "        self.p_out_deterministic = p_out_deterministic\n",
    "        self.RW_order = RW_order\n",
    "\n",
    "\n",
    "    def obs_discrimination(self):\n",
    "        \"\"\"Defines the set of observations, whether they are censored or not, which timesteps are not observed\n",
    "        and the lower and upper bounds of the uniform distribution.\n",
    "\n",
    "        \"\"\"\n",
    "        self.unobserved_indexes = np.where(np.isnan(self.observations))[0]\n",
    "\n",
    "        if len(self.censoring_threshold_loq_vect)>0:\n",
    "            self.observations_below_LoD = np.where(self.observations<=self.censoring_threshold_lod_vect)[0]\n",
    "            self.observations_above_LoQ = np.where(self.observations>self.censoring_threshold_loq_vect)[0]\n",
    "            self.observations_between_LoQD = np.where((self.observations>self.censoring_threshold_lod_vect) & (self.observations<=self.censoring_threshold_loq_vect))[0]\n",
    "        else:\n",
    "            self.observations_below_LoD = np.where(self.observations<=self.censoring_threshold_lod_vect)[0]\n",
    "            self.observations_above_LoQ = np.where(self.observations>self.censoring_threshold_lod_vect)[0]\n",
    "            self.observations_between_LoQD = np.array([])\n",
    "\n",
    "        self.T_ronde = np.setdiff1d(np.arange(self.observations.shape[0]), self.unobserved_indexes)\n",
    "        self.borne_inf, self.borne_sup = np.nanmin(self.observations) - 2*np.nanstd(self.observations), np.nanmax(self.observations) + 2*np.nanstd(self.observations)\n",
    "\n",
    "\n",
    "    def model_definition(self):\n",
    "        \"\"\"Defines the model parameters and observation in pyMC's framework.\n",
    "\n",
    "        \"\"\"\n",
    "        self.obs_discrimination()\n",
    "\n",
    "        with pm.Model() as self.SCOU_model:\n",
    "            ### ----- Priors definition ----- ###\n",
    "            sig = pm.InverseGamma('sig', alpha=2, beta=1) # Latent process innovation's drift\n",
    "            eps = pm.InverseGamma('eps', alpha=2, beta=1) # Observations standard deviation w.r.t latent process\n",
    "            if self.p_out_frozen:\n",
    "                p_out = self.p_out_deterministic # Outliers a priori proportion can be frozen to a deterministic value\n",
    "            else:\n",
    "                p_out = pm.Beta('p_out', alpha=2, beta=5) # Outliers a priori proportion\n",
    "\n",
    "            init_mean = np.nanmean(self.observations)\n",
    "            init_std = 5\n",
    "            init_dist = pm.Normal.dist(init_mean, init_std, shape=self.n_steps)\n",
    "            if self.RW_order==1:\n",
    "                latent = pm.AR(\"latent\", rho=np.array([1]), sigma=sig, shape=self.n_steps, init_dist=init_dist) # Latent process X[t] defined as (AR(1))\n",
    "            elif self.RW_order==2:\n",
    "                latent = pm.AR(\"latent\", rho=np.array([2, -1]), sigma=sig, shape=self.n_steps, init_dist=init_dist) # Latent process X[t] defined as (AR(2))\n",
    "\n",
    "            ### ----- Uncensored data handling ----- ###\n",
    "            normal_component = pm.Normal.dist(mu=latent[self.observations_above_LoQ], sigma=eps) # Gaussian component for uncensored data\n",
    "            outlier_component = pm.Uniform.dist(lower=self.borne_inf, upper=self.borne_sup) # Uniform component for outliers\n",
    "\n",
    "            ### -----  Uncensored data mixture model definition ----- ###\n",
    "            obs_uncensored = pm.Mixture(\n",
    "                'obs_uncensored',\n",
    "                w=[1 - p_out, p_out],\n",
    "                comp_dists=[normal_component, outlier_component],\n",
    "                observed=self.observations[self.observations_above_LoQ]\n",
    "            )\n",
    "\n",
    "            ### ----- LoD censored data handling ----- ###\n",
    "            normal_LoD_component = pm.DensityDist.dist(\n",
    "                eps, latent[self.observations_below_LoD],\n",
    "                logp=censored_normal_logcdf,\n",
    "                logcdf=censored_normal_logcdf,\n",
    "                class_name=\"normal_LoD_component\"\n",
    "            )\n",
    "\n",
    "            outlier_LoD_component = pm.DensityDist.dist(\n",
    "                self.borne_inf, self.borne_sup,\n",
    "                logp=censored_uniform_logcdf,\n",
    "                logcdf=censored_uniform_logcdf,\n",
    "                class_name=\"outlier_LoD_component\"\n",
    "            )\n",
    "\n",
    "            ### -----  Censored data mixture model definition ----- ###\n",
    "            obs_LoD = pm.Mixture(\n",
    "                'obs_LoD',\n",
    "                w=[1 - p_out, p_out],\n",
    "                comp_dists=[normal_LoD_component, outlier_LoD_component],\n",
    "                observed=self.observations[self.observations_below_LoD]\n",
    "            )\n",
    "\n",
    "            if len(self.censoring_threshold_loq_vect)>0:\n",
    "                ### ----- LoQ censored data handling ----- ###\n",
    "                normal_LoQ_component = pm.DensityDist.dist(\n",
    "                    eps, latent[self.observations_between_LoQD],\n",
    "                    logp=censored_normal_logcdf_LoQ,\n",
    "                    logcdf=censored_normal_logcdf_LoQ,\n",
    "                    class_name=\"normal_LoQ_component\"\n",
    "                )\n",
    "\n",
    "                outlier_LoQ_component = pm.DensityDist.dist(\n",
    "                    self.borne_inf, self.borne_sup,\n",
    "                    logp=censored_uniform_logcdf_LoQ,\n",
    "                    logcdf=censored_uniform_logcdf_LoQ,\n",
    "                    class_name=\"outlier_LoD_component\"\n",
    "                )\n",
    "\n",
    "                loqd_stacked_obs = np.vstack((self.censoring_threshold_lod_vect[self.observations_between_LoQD],\n",
    "                                           self.observations[self.observations_between_LoQD])).T\n",
    "\n",
    "                ### -----  Censored data mixture model definition ----- ###\n",
    "                obs_LoQ = pm.Mixture(\n",
    "                    'obs_LoQ',\n",
    "                    w=[1 - p_out, p_out],\n",
    "                    comp_dists=[normal_LoQ_component, outlier_LoQ_component],\n",
    "                    observed=loqd_stacked_obs\n",
    "                )\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Computes the MCMC estimation of the model parameters using the NUTS sampler.\n",
    "\n",
    "        \"\"\"\n",
    "        self.model_definition()\n",
    "\n",
    "        # InfÃ©rence\n",
    "        with self.SCOU_model:\n",
    "            self.SCOU_traces = pm.sample(self.sampling_iters, tune=self.tuning_iters,\n",
    "                                    chains=self.nb_chains,\n",
    "                                    return_inferencedata=True,\n",
    "                                    random_seed=self.rng,\n",
    "                                    cores=4)\n",
    "\n",
    "        self.params = ['sig', 'eps']\n",
    "        if not self.p_out_frozen:\n",
    "            self.params.append('p_out')\n",
    "\n",
    "        print(\"Raw summary:\")\n",
    "        print(az.summary(self.SCOU_traces, var_names=self.params))\n",
    "        self.params_summary = az.summary(self.SCOU_traces, var_names=self.params)\n",
    "\n",
    "        if self.export_chains:\n",
    "            self.SCOU_traces.to_netcdf(self.export_name)\n",
    "\n",
    "    def predict(self, selected_chains):\n",
    "        \"\"\"Computes the latent distribution, as well as its mean and 95% confidence intervals and pointwise outlier probabilities\n",
    "        for a subset of selected chains.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_chains : {array} of shape (n_selected_chains, ).\n",
    "        The array of indexes of the selected chains, ranging from 0 to self.nb_chains.\n",
    "        \"\"\"\n",
    "        self.n_samples = len(selected_chains)*self.sampling_iters\n",
    "        self.latent_posterior_distribution = self.SCOU_traces['posterior']['latent'].values[selected_chains].reshape(self.n_samples, -1)\n",
    "        self.muX = self.latent_posterior_distribution.mean(axis=0)\n",
    "        self.CIL, self.CIU = get_95CI(self.latent_posterior_distribution)\n",
    "        self.compute_pointwise_outlier_probabilities(selected_chains)\n",
    "\n",
    "        print(\"Best chain combination summary:\")\n",
    "        print(az.summary(self.SCOU_traces.sel(chain=selected_chains), var_names=self.params))\n",
    "\n",
    "    def compute_pointwise_outlier_probabilities(self, selected_chains):\n",
    "        \"\"\"Computes the pointwise outlier probabilities for a subset of selected chains.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_chains : {array} of shape (n_selected_chains, ).\n",
    "        The array of indexes of the selected chains, ranging from 0 to self.nb_chains.\n",
    "        \"\"\"\n",
    "        nb_draws = self.SCOU_traces['posterior']['eps'].values[selected_chains].shape[1] * len(selected_chains)\n",
    "\n",
    "        self.pointwise_pout = np.ones(self.observations.shape[0]) * np.nan\n",
    "        self.pointwise_pout_dist = np.ones((self.observations.shape[0], nb_draws)) * np.nan\n",
    "\n",
    "        # Vectorizing these computations first so that we don't have to repeat them in the next for loop:\n",
    "        this_partial_emission_vector = np.ones(self.observations.shape[0]) * (1/(self.borne_sup - self.borne_inf))\n",
    "        this_partial_emission_vector[self.observations_below_LoD] = ((self.censoring_threshold_lod_vect[self.observations_below_LoD] - self.borne_inf)/(self.borne_sup - self.borne_inf))\n",
    "        if len(self.censoring_threshold_loq_vect)>0:\n",
    "            this_partial_emission_vector[self.observations_between_LoQD] = ((self.censoring_threshold_loq_vect[self.observations_between_LoQD] - self.censoring_threshold_lod_vect[self.observations_between_LoQD])/(self.borne_sup - self.borne_inf))\n",
    "\n",
    "        for this_timestep in self.T_ronde:\n",
    "            xhat_t = self.observations[this_timestep]\n",
    "            x_t = self.SCOU_traces['posterior']['latent'].values[selected_chains].reshape(len(selected_chains)*self.sampling_iters, -1)[:, this_timestep]\n",
    "            this_epsilon = self.SCOU_traces['posterior']['eps'].values[selected_chains].reshape(len(selected_chains)*self.sampling_iters, )[:,]\n",
    "\n",
    "            if self.p_out_frozen:\n",
    "                this_pout = self.p_out_deterministic\n",
    "            else:\n",
    "                this_pout = self.SCOU_traces['posterior']['p_out'].values[selected_chains].reshape(len(selected_chains)*self.sampling_iters, )[:,]\n",
    "\n",
    "            if this_timestep in self.observations_below_LoD:\n",
    "                num = this_pout * this_partial_emission_vector[this_timestep]\n",
    "                denom_not_outlier = (1-this_pout) * approx_standard_normal_cdf_sw(xhat_t, x_t, this_epsilon)\n",
    "                denom = denom_not_outlier + num\n",
    "\n",
    "            elif this_timestep in self.observations_between_LoQD:\n",
    "                num = this_pout * this_partial_emission_vector[this_timestep]\n",
    "                cdf_diff = approx_standard_normal_cdf_sw(xhat_t, x_t, this_epsilon) - approx_standard_normal_cdf_sw(self.censoring_threshold_lod_vect[this_timestep], x_t, this_epsilon)\n",
    "                denom_not_outlier = (1-this_pout) * cdf_diff\n",
    "                denom = denom_not_outlier + num\n",
    "\n",
    "            elif this_timestep in self.observations_above_LoQ:\n",
    "                num = this_pout * this_partial_emission_vector[this_timestep]\n",
    "                denom_not_outlier = (1-this_pout) * normal_distribution_pdf(xhat_t, x_t, this_epsilon)\n",
    "                denom = denom_not_outlier + num\n",
    "\n",
    "            num = np.array(num)\n",
    "            denom = np.array(denom)\n",
    "\n",
    "            self.pointwise_pout_dist[this_timestep] = (num/denom)\n",
    "            self.pointwise_pout[this_timestep] = np.mean(self.pointwise_pout_dist[this_timestep])\n",
    "\n",
    "    def visualize_latents(self, selected_chains):\n",
    "        \"\"\"Plots the mean of the distributions of the latent variable for each chain on a first figure.\n",
    "        Plots the same distribution only for a subset of selected chains on a second figure.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_chains : {array} of shape (n_selected_chains, ).\n",
    "        The array of indexes of the selected chains, ranging from 0 to self.nb_chains.\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        for i in range(self.nb_chains):\n",
    "            plt.plot(self.SCOU_traces['posterior']['latent'][i].mean(axis=0), label=i)\n",
    "\n",
    "        plt.title('Raw chains')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        for i in selected_chains:\n",
    "            plt.plot(self.SCOU_traces['posterior']['latent'][i].mean(axis=0), label=i)\n",
    "\n",
    "        plt.title('Optimized chains')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b379d-5a89-4965-b7b4-b7d3bdfc49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('toy_data.csv', sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
